{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UT-ECE Extended Final Assignment - Answers Notebook (Q1-Q20)\n",
    "\n",
    "This notebook contains completed code and written answers for all sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "HERE = Path.cwd().resolve()\n",
    "CODE_ROOT = None\n",
    "for candidate in [HERE, HERE.parent, HERE.parent.parent]:\n",
    "    if (candidate / 'scripts' / 'full_solution_pipeline.py').exists():\n",
    "        CODE_ROOT = candidate\n",
    "        break\n",
    "    if (candidate / 'code' / 'scripts' / 'full_solution_pipeline.py').exists():\n",
    "        CODE_ROOT = candidate / 'code'\n",
    "        break\n",
    "\n",
    "if CODE_ROOT is None:\n",
    "    raise FileNotFoundError('Run from repo root or code/notebooks so project root can be resolved.')\n",
    "\n",
    "sys.path.insert(0, str(CODE_ROOT / 'scripts'))\n",
    "\n",
    "from full_solution_pipeline import (\n",
    "    load_dataset,\n",
    "    leakage_diagnostics,\n",
    "    simulate_optimizers,\n",
    "    plot_ravine_paths,\n",
    "    run_q4_svm_and_pruning,\n",
    "    run_q5_unsupervised,\n",
    "    run_q6_capstone,\n",
    "    run_q15_calibration_threshold,\n",
    "    run_q16_drift_monitoring,\n",
    "    run_q17_recourse_analysis,\n",
    "    run_all,\n",
    ")\n",
    "from q18_temporal import run_q18_temporal_backtesting\n",
    "from q19_uncertainty import run_q19_uncertainty_quantification\n",
    "from q20_fairness_mitigation import run_q20_fairness_mitigation\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "RANDOM_STATE = 42\n",
    "PROFILE = 'balanced'\n",
    "\n",
    "DATA_PATH = CODE_ROOT / 'data' / 'GlobalTechTalent_50k.csv'\n",
    "FIG_DIR = CODE_ROOT / 'figures'\n",
    "SOL_DIR = CODE_ROOT / 'solutions'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(DATA_PATH)\n",
    "print('Shape:', df.shape)\n",
    "print('Columns:', len(df.columns))\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2eeb4c",
   "metadata": {},
   "source": [
    "## Script-Backed Workflow\n",
    "\n",
    "This notebook is wired to use the official project scripts in `code/scripts` for reproducible runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "SCRIPTS_DIR = CODE_ROOT / 'scripts'\n",
    "\n",
    "def run_script(script_name: str, *args: str):\n",
    "    cmd = [sys.executable, str(SCRIPTS_DIR / script_name), *args]\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    result = subprocess.run(cmd, cwd=str(CODE_ROOT), capture_output=True, text=True)\n",
    "    print(result.stdout[-2000:])\n",
    "    if result.returncode != 0:\n",
    "        print(result.stderr[-2000:])\n",
    "        raise RuntimeError(f'Script failed with code {result.returncode}: {script_name}')\n",
    "    return result\n",
    "\n",
    "script_commands = {\n",
    "    'full_pipeline_fast': ['full_solution_pipeline.py', '--profile', 'fast', '--enable-q18', '--enable-q19', '--enable-q20'],\n",
    "    'baseline_explainability': ['train_and_explain.py'],\n",
    "    'q18_temporal': ['q18_temporal.py'],\n",
    "    'q19_uncertainty': ['q19_uncertainty.py'],\n",
    "    'q20_fairness': ['q20_fairness_mitigation.py'],\n",
    "    'export_report_metrics': ['report_metrics_export.py', '--run-summary', str(SOL_DIR / 'run_summary.json')],\n",
    "}\n",
    "script_commands\n",
    "\n",
    "# Example (uncomment to execute):\n",
    "# run_script(*script_commands['full_pipeline_fast'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adff3a4",
   "metadata": {},
   "source": [
    "## Q1 - Data Science Lifecycle and Problem Framing\n",
    "\n",
    "### Full Answer\n",
    "The problem is a supervised binary classification task: predict `Migration_Status` to support policy and resource planning. The lifecycle is: (1) business framing and harm analysis, (2) ingestion with schema contracts, (3) data quality checks and leakage screening, (4) feature engineering with point-in-time validity, (5) model training/tuning, (6) holdout and temporal validation, (7) explainability/fairness evaluation, (8) deployment with monitoring and rollback.\n",
    "\n",
    "Key success metrics are ROC-AUC and F1 for discrimination, calibration metrics (ECE/Brier) for decision reliability, and subgroup disparity metrics for responsible deployment. Leakage diagnostics indicate `Visa_Approval_Date` is direct post-outcome leakage and must be removed from training/inference.\n",
    "\n",
    "Assumptions: labels are correctly timestamped, cohorts are representative, and feature collection policy is stable. Failure modes: temporal leakage, concept drift, and subgroup performance regression after policy changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32eb735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 starter\n",
    "q1_leakage = leakage_diagnostics(df)\n",
    "q1_leakage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abfd4c",
   "metadata": {},
   "source": [
    "## Q2 - Python Data Operations and EDA\n",
    "\n",
    "### Full Answer\n",
    "The EDA implementation includes schema audit (dtype, null %, uniqueness), duplicate checks, outlier-rate ranking via IQR, and targeted plots tied to decision use. This is not decorative EDA: each artifact is linked to model risk or feature design.\n",
    "\n",
    "Findings from the implemented block:\n",
    "- Data quality summary captures row/column counts, duplicates, and base migration rate.\n",
    "- Outlier diagnostics identify which numeric features have the highest tail risk and should be robust-scaled or winsorized if needed.\n",
    "- Country-level migration-rate slices and feature-vs-target plots reveal non-uniform behavior that motivates subgroup evaluation.\n",
    "- Reusable preprocessing function enforces deterministic cleaning and leakage drop before modeling.\n",
    "\n",
    "Assumptions: missingness is mostly ignorable after imputation and feature semantics are stable. Limitations: IQR rules can over-flag heavy tails; global summaries can hide minority-cohort issues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48804084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 complete: robust EDA + reusable preprocessing helper\n",
    "from IPython.display import display\n",
    "\n",
    "# Reusable utility requested by rubric: deterministic, testable preprocessing entry-point\n",
    "def preprocess_for_tabular_model(data: pd.DataFrame, target: str = 'Migration_Status'):\n",
    "    work = data.copy()\n",
    "    if target not in work.columns:\n",
    "        raise ValueError(f\"Missing target column: {target}\")\n",
    "\n",
    "    # Remove direct leakage if present\n",
    "    if 'Visa_Approval_Date' in work.columns:\n",
    "        work = work.drop(columns=['Visa_Approval_Date'])\n",
    "\n",
    "    # Basic cleanup\n",
    "    work = work.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    cat_cols = work.select_dtypes(include=['object', 'string', 'category', 'bool']).columns.tolist()\n",
    "    num_cols = [c for c in work.columns if c not in cat_cols + [target]]\n",
    "\n",
    "    for c in num_cols:\n",
    "        work[c] = work[c].fillna(work[c].median())\n",
    "    for c in cat_cols:\n",
    "        mode = work[c].mode(dropna=True)\n",
    "        work[c] = work[c].fillna(mode.iloc[0] if not mode.empty else 'Unknown')\n",
    "\n",
    "    X = work.drop(columns=[target])\n",
    "    y = work[target].astype(int)\n",
    "    return X, y, {'numeric_cols': num_cols, 'categorical_cols': cat_cols, 'rows': len(work)}\n",
    "\n",
    "# Q2A: schema + data quality audit\n",
    "schema_table = pd.DataFrame({\n",
    "    'dtype': df.dtypes.astype(str),\n",
    "    'null_pct': (df.isna().mean() * 100).round(2),\n",
    "    'n_unique': df.nunique(dropna=False),\n",
    "}).sort_values('null_pct', ascending=False)\n",
    "\n",
    "quality_summary = {\n",
    "    'rows': int(df.shape[0]),\n",
    "    'cols': int(df.shape[1]),\n",
    "    'duplicate_rows': int(df.duplicated().sum()),\n",
    "    'target_rate': float(df['Migration_Status'].mean()),\n",
    "}\n",
    "\n",
    "print('Q2 quality summary:', quality_summary)\n",
    "display(schema_table.head(12))\n",
    "\n",
    "# Q2B: outlier diagnostics (IQR rates on numeric predictors)\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in ['Migration_Status', 'UserID']]\n",
    "outlier_rows = []\n",
    "for c in num_cols:\n",
    "    q1, q3 = df[c].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lo, hi = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    rate = ((df[c] < lo) | (df[c] > hi)).mean()\n",
    "    outlier_rows.append({'feature': c, 'iqr_outlier_rate': float(rate)})\n",
    "outlier_table = pd.DataFrame(outlier_rows).sort_values('iqr_outlier_rate', ascending=False)\n",
    "display(outlier_table.head(8))\n",
    "\n",
    "# Q2C: targeted EDA visuals\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "sns.histplot(df['Research_Citations'], bins=40, ax=axes[0], color='#1f77b4')\n",
    "axes[0].set_title('Research_Citations Distribution')\n",
    "\n",
    "sns.boxplot(x='Migration_Status', y='Industry_Experience', data=df, ax=axes[1], palette='Set2')\n",
    "axes[1].set_title('Experience vs Migration Status')\n",
    "\n",
    "country_rate = (\n",
    "    df.groupby('Country_Origin', as_index=False)['Migration_Status']\n",
    "    .mean()\n",
    "    .sort_values('Migration_Status', ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "sns.barplot(data=country_rate, x='Migration_Status', y='Country_Origin', ax=axes[2], color='#2ca02c')\n",
    "axes[2].set_title('Top-10 Country Migration Rates')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "X_q2, y_q2, prep_meta_q2 = preprocess_for_tabular_model(df)\n",
    "q2_info = {\n",
    "    'quality_summary': quality_summary,\n",
    "    'top_outlier_feature': outlier_table.iloc[0].to_dict(),\n",
    "    'preprocess_metadata': prep_meta_q2,\n",
    "}\n",
    "q2_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1279a",
   "metadata": {},
   "source": [
    "## Q3 - Scientific Studies and Statistical Inference\n",
    "\n",
    "### Full Answer\n",
    "This dataset is observational, so we should interpret relationships as associations unless an identification strategy supports causal claims. A valid inference workflow here is: pre-specify hypotheses, run statistical tests, report confidence intervals/effect sizes, and state assumptions explicitly.\n",
    "\n",
    "For coefficient reporting, significance requires both low p-value and confidence interval excluding zero. Example interpretation pattern: if CI is fully positive and p < 0.05, we reject the null of no effect and report direction/magnitude with uncertainty bounds.\n",
    "\n",
    "Assumptions: independent sampling (or corrected dependence), stable data-generating process for the analyzed window, and no severe unobserved confounding for causal language. Failure modes: p-hacking via repeated testing, confounding interpreted as causation, and overconfident conclusions without temporal robustness checks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c510ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 starter\n",
    "paths = simulate_optimizers()\n",
    "plot_ravine_paths(paths, FIG_DIR / 'q3_ravine_optimizers.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8152b4",
   "metadata": {},
   "source": [
    "## Q4 - Visualization Design and Storytelling\n",
    "\n",
    "### Full Answer\n",
    "The Q4 visuals are decision-oriented: the SVM gamma sweep explains model-capacity tradeoffs, and the pruning curve explains complexity control in trees. Correct visual design choices include readable axes, consistent scales, explicit legends, and avoiding truncation that exaggerates small differences.\n",
    "\n",
    "Narrative interpretation:\n",
    "- As gamma increases in RBF-SVM, training fit typically rises while validation can degrade after an optimum (overfitting signal).\n",
    "- In pruning, increasing `ccp_alpha` reduces complexity and often improves validation until underfitting begins.\n",
    "\n",
    "Assumptions: validation split is representative and preprocessing parity is maintained. Limitation: a single split can be noisy; cross-validation and subgroup slices should back up final model decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 starter\n",
    "q4_info = run_q4_svm_and_pruning(df, FIG_DIR)\n",
    "q4_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e213a",
   "metadata": {},
   "source": [
    "## Q5 - SQL Advanced Querying\n",
    "\n",
    "### Full Answer\n",
    "Advanced SQL is used for temporal and cohort-aware analytics. Window functions support moving averages and within-country ranking, which are suitable for longitudinal citation momentum analysis.\n",
    "\n",
    "Key query logic:\n",
    "- `AVG(...) OVER (PARTITION BY Country_Origin ORDER BY Year ROWS BETWEEN 2 PRECEDING AND CURRENT ROW)` computes rolling citation velocity.\n",
    "- `DENSE_RANK() OVER (PARTITION BY Country_Origin ORDER BY moving_avg_citations DESC)` yields country-relative standing.\n",
    "\n",
    "Why this matters: policy teams need rank-within-cohort, not only global means. Assumptions: year semantics are clean and no duplicate event rows distort windows. Failure modes: late-arriving records changing historical windows and unmodeled cohort composition shifts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 starter\n",
    "q5_info = run_q5_unsupervised(df, FIG_DIR)\n",
    "q5_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd334501",
   "metadata": {},
   "source": [
    "## Q6 - Leakage and Big-Data Architecture\n",
    "\n",
    "### Full Answer\n",
    "Leakage governance is mandatory before architecture scaling. `Visa_Approval_Date` is direct leakage and must be excluded. Other fields (`Last_Login_Region`, `Passport_Renewal_Status`) require timestamp policy checks before use.\n",
    "\n",
    "Production architecture recommendation:\n",
    "- Batch + streaming ingestion with schema contracts.\n",
    "- Feature store with point-in-time joins for train/serve parity.\n",
    "- Model registry + reproducible training pipeline.\n",
    "- Real-time/nearline monitoring for drift, calibration, and subgroup metrics.\n",
    "- Rollback playbook with threshold-triggered incident response.\n",
    "\n",
    "Capstone outputs (metrics + explanations + subgroup slices) support technical and governance review. Limitations: proxy leakage can remain even after obvious columns are removed; continuous audit is required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe98b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 starter\n",
    "q6_info = run_q6_capstone(df, FIG_DIR, SOL_DIR)\n",
    "q6_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cfb069",
   "metadata": {},
   "source": [
    "## Q7 - Linear/Logistic Models and Elastic Net\n",
    "\n",
    "### Full Answer\n",
    "Elastic Net combines L1 (sparsity/feature selection) and L2 (stability under collinearity) regularization, making it suitable for mixed, correlated tabular features. In this notebook, both logistic (classification) and linear (regression) Elastic Net variants are run to show predictive and shrinkage behavior.\n",
    "\n",
    "Interpretation of results:\n",
    "- Classification metrics (ROC-AUC, F1, precision, recall) quantify thresholded and ranking quality.\n",
    "- Nonzero-coefficient ratio shows regularization strength in practice.\n",
    "- Regression metrics (R2/MAE) provide an interpretable shrinkage baseline.\n",
    "\n",
    "Assumptions: linear signal in transformed space and leakage-safe features. Failure modes: underfitting from excessive regularization, calibration mismatch at threshold 0.5, and unstable coefficients under severe shift.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a265d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 complete: linear/logistic models with Elastic Net regularization\n",
    "from sklearn.linear_model import ElasticNet, SGDClassifier\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "work = df.sample(n=min(len(df), 18000), random_state=RANDOM_STATE).copy()\n",
    "X, y = build_features(work, drop_leakage=True)\n",
    "\n",
    "# Keep direct leakage proxies out for a leakage-safe baseline\n",
    "for col in ['Last_Login_Region', 'Passport_Renewal_Status']:\n",
    "    if col in X.columns:\n",
    "        X = X.drop(columns=[col])\n",
    "\n",
    "# Classification (logistic loss + elastic-net penalty)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "pre_q7, _, _ = build_preprocessor(X_train)\n",
    "X_train_enc = pre_q7.fit_transform(X_train)\n",
    "X_test_enc = pre_q7.transform(X_test)\n",
    "\n",
    "log_en = SGDClassifier(\n",
    "    loss='log_loss',\n",
    "    penalty='elasticnet',\n",
    "    alpha=0.0008,\n",
    "    l1_ratio=0.35,\n",
    "    max_iter=3000,\n",
    "    tol=1e-3,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "log_en.fit(X_train_enc, y_train)\n",
    "\n",
    "y_prob = log_en.predict_proba(X_test_enc)[:, 1]\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "# Regression (ElasticNet) on citations for interpretability of shrinkage behavior\n",
    "num = work.select_dtypes(include=[np.number]).copy()\n",
    "num = num.drop(columns=[c for c in ['Visa_Approval_Date'] if c in num.columns], errors='ignore')\n",
    "reg_target = num['Research_Citations']\n",
    "reg_X = num.drop(columns=['Research_Citations', 'Migration_Status', 'UserID'], errors='ignore').fillna(0)\n",
    "\n",
    "rx_train, rx_test, ry_train, ry_test = train_test_split(\n",
    "    reg_X, reg_target, test_size=0.25, random_state=RANDOM_STATE\n",
    ")\n",
    "reg_en = ElasticNet(alpha=0.05, l1_ratio=0.4, random_state=RANDOM_STATE)\n",
    "reg_en.fit(rx_train, ry_train)\n",
    "reg_pred = reg_en.predict(rx_test)\n",
    "\n",
    "q7_metrics = pd.DataFrame([\n",
    "    {\n",
    "        'model': 'ElasticNet-Logistic',\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "    },\n",
    "    {\n",
    "        'model': 'ElasticNet-Regression',\n",
    "        'r2': r2_score(ry_test, reg_pred),\n",
    "        'mae': mean_absolute_error(ry_test, reg_pred),\n",
    "    },\n",
    "])\n",
    "\n",
    "q7_info = {\n",
    "    'classification_nonzero_coef_ratio': float((np.abs(log_en.coef_) > 1e-10).mean()),\n",
    "    'regression_nonzero_coef_ratio': float((np.abs(reg_en.coef_) > 1e-10).mean()),\n",
    "}\n",
    "\n",
    "q7_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e927c3",
   "metadata": {},
   "source": [
    "## Q8 - Optimization: SGD, Momentum, Adam\n",
    "\n",
    "### Full Answer\n",
    "On ill-conditioned ravines, SGD zig-zags due to steep curvature mismatch. Momentum reduces this by accumulating velocity across steps, while Adam further adapts per-parameter step sizes using first/second moments.\n",
    "\n",
    "From the convergence diagnostics:\n",
    "- Log-loss curves quantify speed and stability differences.\n",
    "- Iteration-to-threshold table shows practical optimization efficiency.\n",
    "- Final-loss comparison ranks optimizer effectiveness on this objective.\n",
    "\n",
    "Conclusion: Adam and Momentum generally converge faster than plain SGD in this geometry, but optimizer choice should still be validated for generalization, not only training loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f79033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8 complete: SGD vs Momentum vs Adam convergence diagnostics on ravine loss\n",
    "paths_q8 = simulate_optimizers(steps=180)\n",
    "a_q8 = float(paths_q8['a'][0])\n",
    "b_q8 = float(paths_q8['b'][0])\n",
    "\n",
    "def ravine_loss_curve(path):\n",
    "    return 0.5 * (a_q8 * path[:, 0] ** 2 + b_q8 * path[:, 1] ** 2)\n",
    "\n",
    "loss_curves = {k: ravine_loss_curve(paths_q8[k]) for k in ['sgd', 'momentum', 'adam']}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for k, color in [('sgd', '#2a9d8f'), ('momentum', '#e76f51'), ('adam', '#264653')]:\n",
    "    plt.plot(loss_curves[k], label=k.upper(), linewidth=2, color=color)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Ravine loss (log scale)')\n",
    "plt.title('Q8: Optimizer Convergence on Ill-Conditioned Ravine')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "threshold = 1e-3\n",
    "q8_table = []\n",
    "for k in ['sgd', 'momentum', 'adam']:\n",
    "    curve = loss_curves[k]\n",
    "    hit = np.where(curve <= threshold)[0]\n",
    "    q8_table.append({\n",
    "        'optimizer': k,\n",
    "        'final_loss': float(curve[-1]),\n",
    "        'iters_to_loss<=1e-3': int(hit[0]) if len(hit) else None,\n",
    "    })\n",
    "q8_table = pd.DataFrame(q8_table).sort_values('final_loss')\n",
    "q8_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff14a",
   "metadata": {},
   "source": [
    "## Q9 - SVM/KNN/Trees/Boosting Comparison\n",
    "\n",
    "### Full Answer\n",
    "A fair model-family comparison uses one split protocol, aligned preprocessing, and consistent metrics. Implemented models include SVM-RBF, KNN, Random Forest, and Gradient Boosting.\n",
    "\n",
    "Interpretation framework:\n",
    "- ROC-AUC for ranking quality.\n",
    "- F1/precision/recall for threshold behavior.\n",
    "- Accuracy as secondary due to class-balance sensitivity.\n",
    "\n",
    "Model selection should favor the best validation utility under policy constraints (for example, penalizing false negatives more heavily). Limitations: results are split-sensitive; cross-validation and calibration checks should confirm the chosen model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c42e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9 complete: supervised family comparison under a common split/protocol\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sample = df.sample(n=min(len(df), 12000), random_state=RANDOM_STATE).copy()\n",
    "X, y = build_features(sample, drop_leakage=True)\n",
    "\n",
    "for col in ['Last_Login_Region', 'Passport_Renewal_Status']:\n",
    "    if col in X.columns:\n",
    "        X = X.drop(columns=[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "models = {\n",
    "    'SVM-RBF': SVC(kernel='rbf', C=2.0, gamma='scale', probability=True, random_state=RANDOM_STATE),\n",
    "    'KNN-31': KNeighborsClassifier(n_neighbors=31, weights='distance'),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=250, max_depth=14, random_state=RANDOM_STATE, n_jobs=4),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in models.items():\n",
    "    pre, _, _ = build_preprocessor(X_train)\n",
    "    pipe = Pipeline([('pre', pre), ('model', model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    prob = pipe.predict_proba(X_test)[:, 1]\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "    rows.append({\n",
    "        'model': name,\n",
    "        'roc_auc': roc_auc_score(y_test, prob),\n",
    "        'f1': f1_score(y_test, pred),\n",
    "        'precision': precision_score(y_test, pred),\n",
    "        'recall': recall_score(y_test, pred),\n",
    "        'accuracy': accuracy_score(y_test, pred),\n",
    "    })\n",
    "\n",
    "q9_results = pd.DataFrame(rows).sort_values('roc_auc', ascending=False).reset_index(drop=True)\n",
    "q9_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e6033e",
   "metadata": {},
   "source": [
    "## Q10 - Dimensionality Reduction\n",
    "\n",
    "### Full Answer\n",
    "PCA quantifies variance retention and supports compression with interpretable tradeoffs. Random projection is added as an efficiency baseline that can preserve geometry approximately with lower interpretability.\n",
    "\n",
    "Evidence used:\n",
    "- PCA cumulative explained-variance curve to choose component count.\n",
    "- Clustering-silhouette comparison in original vs reduced spaces to evaluate structure retention.\n",
    "\n",
    "Decision rule: choose the smallest dimensionality that preserves needed utility (classification/clustering) and operational latency constraints. Failure mode: reducing dimensions too aggressively can remove minority-pattern signal and harm fairness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10 complete: PCA + random projection tradeoff diagnostics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in ['Migration_Status', 'UserID', 'Visa_Approval_Date']]\n",
    "X_num = df[num_cols].fillna(df[num_cols].median(numeric_only=True))\n",
    "\n",
    "# Sample to keep runtime predictable\n",
    "X_num = X_num.sample(n=min(len(X_num), 15000), random_state=RANDOM_STATE)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_num)\n",
    "\n",
    "pca = PCA(n_components=min(10, X_scaled.shape[1]), random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "cum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "rp = GaussianRandomProjection(n_components=min(5, X_scaled.shape[1]), random_state=RANDOM_STATE)\n",
    "X_rp = rp.fit_transform(X_scaled)\n",
    "\n",
    "# Geometry retention proxy: silhouette after clustering in each representation\n",
    "k = 4\n",
    "labels_orig = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10).fit_predict(X_scaled)\n",
    "labels_pca = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10).fit_predict(X_pca[:, :5])\n",
    "labels_rp = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10).fit_predict(X_rp)\n",
    "\n",
    "q10_table = pd.DataFrame([\n",
    "    {'representation': 'original_scaled', 'silhouette': silhouette_score(X_scaled, labels_orig)},\n",
    "    {'representation': 'pca_5', 'silhouette': silhouette_score(X_pca[:, :5], labels_pca)},\n",
    "    {'representation': 'random_projection_5', 'silhouette': silhouette_score(X_rp, labels_rp)},\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(np.arange(1, len(cum_var) + 1), cum_var, marker='o')\n",
    "plt.axhline(0.9, color='black', linestyle='--', linewidth=1, label='90% variance')\n",
    "plt.xlabel('Number of principal components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.title('Q10: PCA Explained Variance Profile')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "q10_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2417179c",
   "metadata": {},
   "source": [
    "## Q11 - Clustering: KMeans and DBSCAN\n",
    "\n",
    "### Full Answer\n",
    "KMeans and DBSCAN answer different structure assumptions: centroid-based compact clusters vs density-connected clusters with noise handling.\n",
    "\n",
    "Implemented evidence:\n",
    "- KMeans elbow (inertia) and silhouette across k for compactness/separation tradeoff.\n",
    "- DBSCAN sensitivity sweep over `eps` and `min_samples` with cluster count, noise rate, and non-noise silhouette.\n",
    "\n",
    "Interpretation: if DBSCAN marks high noise under many settings, structure may be weakly density-separable; if KMeans silhouette is stable at a given k, centroid segmentation is more actionable. Limitations: both are scale-sensitive and descriptive, not causal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff40ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11 complete: KMeans and DBSCAN with sensitivity analysis\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in ['Migration_Status', 'UserID', 'Visa_Approval_Date']]\n",
    "X_num = df[num_cols].fillna(df[num_cols].median(numeric_only=True))\n",
    "X_num = X_num.sample(n=min(len(X_num), 12000), random_state=RANDOM_STATE)\n",
    "X_scaled = StandardScaler().fit_transform(X_num)\n",
    "\n",
    "# KMeans elbow + silhouette evidence\n",
    "k_values = list(range(2, 9))\n",
    "km_rows = []\n",
    "for k in k_values:\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    km_rows.append({\n",
    "        'k': k,\n",
    "        'inertia': km.inertia_,\n",
    "        'silhouette': silhouette_score(X_scaled, labels),\n",
    "    })\n",
    "q11_kmeans = pd.DataFrame(km_rows)\n",
    "\n",
    "# DBSCAN sensitivity sweep\n",
    "db_rows = []\n",
    "for eps in [0.8, 1.0, 1.2, 1.4]:\n",
    "    for ms in [5, 10, 20]:\n",
    "        db = DBSCAN(eps=eps, min_samples=ms)\n",
    "        labels = db.fit_predict(X_scaled)\n",
    "        non_noise = labels != -1\n",
    "        n_clusters = len(set(labels[non_noise])) if non_noise.any() else 0\n",
    "        noise_rate = float((labels == -1).mean())\n",
    "        sil = np.nan\n",
    "        if n_clusters >= 2 and non_noise.sum() >= 20:\n",
    "            sil = silhouette_score(X_scaled[non_noise], labels[non_noise])\n",
    "        db_rows.append({\n",
    "            'eps': eps,\n",
    "            'min_samples': ms,\n",
    "            'clusters_found': int(n_clusters),\n",
    "            'noise_rate': noise_rate,\n",
    "            'silhouette_non_noise': sil,\n",
    "        })\n",
    "q11_dbscan = pd.DataFrame(db_rows).sort_values(['silhouette_non_noise', 'clusters_found'], ascending=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(q11_kmeans['k'], q11_kmeans['inertia'], marker='o')\n",
    "axes[0].set_title('KMeans Elbow (Inertia)')\n",
    "axes[0].set_xlabel('k')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "\n",
    "axes[1].plot(q11_kmeans['k'], q11_kmeans['silhouette'], marker='o', color='#2ca02c')\n",
    "axes[1].set_title('KMeans Silhouette')\n",
    "axes[1].set_xlabel('k')\n",
    "axes[1].set_ylabel('Silhouette')\n",
    "plt.tight_layout()\n",
    "\n",
    "q11_summary = {\n",
    "    'best_k_by_silhouette': int(q11_kmeans.loc[q11_kmeans['silhouette'].idxmax(), 'k']),\n",
    "    'best_dbscan_row': q11_dbscan.iloc[0].to_dict(),\n",
    "}\n",
    "q11_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c527777",
   "metadata": {},
   "source": [
    "## Q12 - Neural Networks and Sequence Modeling\n",
    "\n",
    "### Full Answer\n",
    "Two complementary baselines are used:\n",
    "- Tabular MLP for nonlinear interactions in structured features.\n",
    "- Lightweight sequence/text proxy via n-gram TF-IDF + logistic classifier on profile-derived text fields.\n",
    "\n",
    "Quantitative outputs include ROC-AUC/F1/accuracy and MLP loss curve diagnostics. This provides both tabular deep-learning and sequence-style modeling coverage for the assignment.\n",
    "\n",
    "Limitations: the text proxy is not a full transformer/RNN pipeline and may miss deep semantics; MLP performance depends on hyperparameter budget and may require stronger regularization or architecture tuning for best generalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12 complete: tabular NN baseline + lightweight text/sequence proxy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sample = df.sample(n=min(len(df), 16000), random_state=RANDOM_STATE).copy()\n",
    "X, y = build_features(sample, drop_leakage=True)\n",
    "\n",
    "# 1) Tabular neural network baseline\n",
    "for col in ['Last_Login_Region', 'Passport_Renewal_Status']:\n",
    "    if col in X.columns:\n",
    "        X = X.drop(columns=[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "pre_q12, _, _ = build_preprocessor(X_train)\n",
    "X_train_enc = pre_q12.fit_transform(X_train)\n",
    "X_test_enc = pre_q12.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='relu',\n",
    "    alpha=1e-4,\n",
    "    learning_rate_init=1e-3,\n",
    "    max_iter=60,\n",
    "    early_stopping=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "mlp.fit(X_train_enc, y_train)\n",
    "mlp_prob = mlp.predict_proba(X_test_enc)[:, 1]\n",
    "mlp_pred = (mlp_prob >= 0.5).astype(int)\n",
    "\n",
    "# 2) Sequence/text equivalent using token-order aware n-grams from profile text\n",
    "text_series = (\n",
    "    sample['Field'].astype(str) + ' | ' +\n",
    "    sample['Education_Level'].astype(str) + ' | ' +\n",
    "    sample['Country_Origin'].astype(str)\n",
    ")\n",
    "xt_train, xt_test, yt_train, yt_test = train_test_split(\n",
    "    text_series, sample['Migration_Status'].astype(int),\n",
    "    test_size=0.25, random_state=RANDOM_STATE, stratify=sample['Migration_Status'].astype(int)\n",
    ")\n",
    "\n",
    "text_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), min_df=5)),\n",
    "    ('clf', LogisticRegression(max_iter=400, class_weight='balanced')),\n",
    "])\n",
    "text_pipe.fit(xt_train, yt_train)\n",
    "text_prob = text_pipe.predict_proba(xt_test)[:, 1]\n",
    "text_pred = (text_prob >= 0.5).astype(int)\n",
    "\n",
    "q12_results = pd.DataFrame([\n",
    "    {\n",
    "        'model': 'Tabular-MLP',\n",
    "        'roc_auc': roc_auc_score(y_test, mlp_prob),\n",
    "        'f1': f1_score(y_test, mlp_pred),\n",
    "        'accuracy': accuracy_score(y_test, mlp_pred),\n",
    "    },\n",
    "    {\n",
    "        'model': 'Text-ngram baseline',\n",
    "        'roc_auc': roc_auc_score(yt_test, text_prob),\n",
    "        'f1': f1_score(yt_test, text_pred),\n",
    "        'accuracy': accuracy_score(yt_test, text_pred),\n",
    "    },\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(mlp.loss_curve_, color='#8c564b')\n",
    "plt.title('Q12: Tabular MLP Training Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.tight_layout()\n",
    "\n",
    "q12_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeacdadb",
   "metadata": {},
   "source": [
    "## Q13 - Language Models and LLM Agents\n",
    "\n",
    "### Full Answer\n",
    "A production-ready LLM-agent design should be evaluated on faithfulness, safety, latency, cost, and operational complexity. The notebook scorecard compares three patterns: single-pass LLM, RAG with citation checks, and planner-retriever-verifier.\n",
    "\n",
    "For high-stakes analytical workflows, planner-retriever-verifier or strong RAG is preferable because grounded retrieval and verification reduce hallucination risk. Deployment gates should require minimum safety/faithfulness thresholds before enabling autonomous actions.\n",
    "\n",
    "Governance controls: source citation requirements, refusal policy for unsupported claims, human override channel, and audit logs of prompts/tools/actions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc0e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13 complete: LLM-agent design with quantitative scorecard\n",
    "agent_designs = pd.DataFrame([\n",
    "    {\n",
    "        'design': 'Single-pass LLM',\n",
    "        'faithfulness_score': 0.55,\n",
    "        'latency_score': 0.90,\n",
    "        'cost_score': 0.92,\n",
    "        'safety_score': 0.45,\n",
    "        'ops_complexity_score': 0.90,\n",
    "    },\n",
    "    {\n",
    "        'design': 'RAG + citation checks',\n",
    "        'faithfulness_score': 0.80,\n",
    "        'latency_score': 0.70,\n",
    "        'cost_score': 0.72,\n",
    "        'safety_score': 0.78,\n",
    "        'ops_complexity_score': 0.65,\n",
    "    },\n",
    "    {\n",
    "        'design': 'Planner + Retriever + Verifier',\n",
    "        'faithfulness_score': 0.88,\n",
    "        'latency_score': 0.58,\n",
    "        'cost_score': 0.60,\n",
    "        'safety_score': 0.88,\n",
    "        'ops_complexity_score': 0.50,\n",
    "    },\n",
    "])\n",
    "\n",
    "# Weighted utility for policy/compliance-sensitive setting\n",
    "weights = {\n",
    "    'faithfulness_score': 0.35,\n",
    "    'safety_score': 0.25,\n",
    "    'latency_score': 0.15,\n",
    "    'cost_score': 0.10,\n",
    "    'ops_complexity_score': 0.15,\n",
    "}\n",
    "\n",
    "agent_designs['weighted_utility'] = sum(agent_designs[k] * w for k, w in weights.items())\n",
    "agent_designs = agent_designs.sort_values('weighted_utility', ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(data=agent_designs, x='weighted_utility', y='design', palette='viridis')\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Q13: Agent Architecture Utility Comparison')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Governance gates for deployment decisioning\n",
    "deployment_gate = {\n",
    "    'min_faithfulness': 0.75,\n",
    "    'min_safety': 0.75,\n",
    "}\n",
    "agent_designs['passes_gate'] = (\n",
    "    (agent_designs['faithfulness_score'] >= deployment_gate['min_faithfulness']) &\n",
    "    (agent_designs['safety_score'] >= deployment_gate['min_safety'])\n",
    ")\n",
    "\n",
    "agent_designs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49cdb40",
   "metadata": {},
   "source": [
    "## Q14 - Ethics, Fairness, and Governance\n",
    "\n",
    "### Full Answer\n",
    "Responsible deployment requires explicit subgroup auditing and escalation policy. The notebook computes subgroup metrics by `Country_Origin` and `Education_Level`, including positive rate, TPR/FPR, and demographic parity gap summaries.\n",
    "\n",
    "Governance policy should include:\n",
    "- Trigger thresholds for disparity review.\n",
    "- Human-in-the-loop approval for high-impact decisions.\n",
    "- Documentation of acceptable interventions and override mechanisms.\n",
    "- Periodic re-audits after model/data/policy updates.\n",
    "\n",
    "Limitations: single-axis subgroup analysis can miss intersectional harms; small subgroup sample sizes can make disparity estimates unstable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14 complete: fairness audit + governance policy table\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "audit_df = df.sample(n=min(len(df), 20000), random_state=RANDOM_STATE).copy()\n",
    "X, y = build_features(audit_df, drop_leakage=True)\n",
    "\n",
    "# Remove potentially post-outcome proxies for policy-safe baseline\n",
    "for col in ['Last_Login_Region', 'Passport_Renewal_Status']:\n",
    "    if col in X.columns:\n",
    "        X = X.drop(columns=[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "pre_q14, _, _ = build_preprocessor(X_train)\n",
    "clf = Pipeline([\n",
    "    ('pre', pre_q14),\n",
    "    ('lr', LogisticRegression(max_iter=500, class_weight='balanced')),\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "base_auc = roc_auc_score(y_test, proba)\n",
    "\n",
    "audit = X_test[['Country_Origin', 'Education_Level']].copy()\n",
    "audit['y_true'] = y_test.values\n",
    "audit['y_pred'] = pred\n",
    "audit['score'] = proba\n",
    "\n",
    "def subgroup_metrics(frame: pd.DataFrame, group_col: str, top_n: int = 8) -> pd.DataFrame:\n",
    "    counts = frame[group_col].value_counts().head(top_n).index\n",
    "    rows = []\n",
    "    for g in counts:\n",
    "        sub = frame[frame[group_col] == g]\n",
    "        tn, fp, fn, tp = confusion_matrix(sub['y_true'], sub['y_pred'], labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else np.nan\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else np.nan\n",
    "        rows.append({\n",
    "            'group': g,\n",
    "            'n': len(sub),\n",
    "            'positive_rate': sub['y_pred'].mean(),\n",
    "            'tpr': tpr,\n",
    "            'fpr': fpr,\n",
    "        })\n",
    "    out = pd.DataFrame(rows)\n",
    "    out['demographic_parity_gap_vs_mean'] = out['positive_rate'] - out['positive_rate'].mean()\n",
    "    return out.sort_values('n', ascending=False)\n",
    "\n",
    "country_audit = subgroup_metrics(audit, 'Country_Origin', top_n=8)\n",
    "edu_audit = subgroup_metrics(audit, 'Education_Level', top_n=6)\n",
    "\n",
    "fairness_summary = {\n",
    "    'overall_auc': float(base_auc),\n",
    "    'country_dp_gap_abs_max': float(country_audit['demographic_parity_gap_vs_mean'].abs().max()),\n",
    "    'education_dp_gap_abs_max': float(edu_audit['demographic_parity_gap_vs_mean'].abs().max()),\n",
    "    'policy_trigger': 'trigger review if any abs demographic parity gap > 0.10 or subgroup TPR gap > 0.12',\n",
    "}\n",
    "\n",
    "fairness_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb8e6b",
   "metadata": {},
   "source": [
    "## Q15 - Calibration and Decision Threshold Policy\n",
    "\n",
    "### Full Answer\n",
    "Calibration determines whether predicted probabilities are decision-reliable. This block provides calibration curve, ECE/Brier diagnostics, and threshold optimization.\n",
    "\n",
    "Policy recommendation:\n",
    "- Report both F1-optimal threshold and asymmetric-cost-optimal threshold.\n",
    "- Choose operational threshold from cost structure (typically FN cost > FP cost in talent-risk settings), not default 0.5.\n",
    "- Recalibrate after drift events or major retrains.\n",
    "\n",
    "Failure mode: high AUC with poor calibration can still produce bad policy decisions if probability outputs are interpreted literally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q15 starter\n",
    "q15_info = run_q15_calibration_threshold(df, FIG_DIR)\n",
    "q15_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc274b",
   "metadata": {},
   "source": [
    "## Q16 - Production Drift Monitoring and Alerting\n",
    "\n",
    "### Full Answer\n",
    "Drift monitoring compares current data to reference baseline and ranks feature shift severity. PSI interpretation used in this project:\n",
    "- PSI < 0.10: low drift\n",
    "- 0.10 <= PSI < 0.25: moderate drift\n",
    "- PSI >= 0.25: high drift\n",
    "\n",
    "Operational policy:\n",
    "- Alert on sustained moderate drift in top features.\n",
    "- Escalate immediately on high drift or simultaneous calibration degradation.\n",
    "- Require retraining decision review with performance and subgroup checks.\n",
    "\n",
    "Limitation: feature drift is not equivalent to performance drift; delayed-label evaluation is required to confirm impact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da93e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q16 starter\n",
    "q16_info = run_q16_drift_monitoring(df, FIG_DIR, SOL_DIR)\n",
    "q16_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b109db",
   "metadata": {},
   "source": [
    "## Q17 - Counterfactual Recourse and Actionability\n",
    "\n",
    "### Full Answer\n",
    "Recourse analysis estimates how near-threshold negative predictions can be flipped by bounded, actionable changes. Key outputs are recourse success rate and median required deltas by feature.\n",
    "\n",
    "Decision use:\n",
    "- Prioritize recommendations on controllable, ethically valid attributes.\n",
    "- Reject recourse actions that rely on immutable or protected characteristics.\n",
    "- Route high-burden or low-feasibility cases to human review.\n",
    "\n",
    "Limitation: mathematically valid counterfactuals are not always socially or operationally feasible; recourse policy must be constrained by real-world actionability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q17 starter\n",
    "q17_info = run_q17_recourse_analysis(df, FIG_DIR, SOL_DIR)\n",
    "q17_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bf638",
   "metadata": {},
   "source": [
    "## Q18 - Temporal Backtesting and Decay Analysis\n",
    "\n",
    "### Full Answer\n",
    "Temporal validation is required to estimate deployment realism under non-stationarity. Rolling folds produce time-ordered AUC/F1 estimates and degradation relative to early folds.\n",
    "\n",
    "Interpretation:\n",
    "- Stable fold metrics indicate robust temporal generalization.\n",
    "- Downward trend indicates decay and motivates shorter retraining cadence.\n",
    "- Coupling with drift features helps diagnose whether degradation is covariate-shift-driven.\n",
    "\n",
    "If true timestamps are weak, fallback ordering must be documented and conclusions treated as lower-confidence temporal evidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q18 starter\n",
    "q18_info = run_q18_temporal_backtesting(\n",
    "    df,\n",
    "    figures_dir=FIG_DIR,\n",
    "    solutions_dir=SOL_DIR,\n",
    "    profile=PROFILE,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "q18_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99594f20",
   "metadata": {},
   "source": [
    "## Q19 - Uncertainty Quantification and Coverage\n",
    "\n",
    "### Full Answer\n",
    "Split-conformal uncertainty quantifies prediction confidence with empirical coverage checks across confidence levels. The outputs include coverage-vs-alpha and interval width metrics.\n",
    "\n",
    "Operational policy:\n",
    "- Define low-confidence band where automated decisions are deferred.\n",
    "- Track under-coverage gap and widen/defer when coverage falls below target.\n",
    "- Re-estimate conformity scores after distribution shift.\n",
    "\n",
    "Assumption: exchangeability between calibration and future data; violations under drift can reduce guarantee quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q19 starter\n",
    "q19_info = run_q19_uncertainty_quantification(\n",
    "    df,\n",
    "    figures_dir=FIG_DIR,\n",
    "    solutions_dir=SOL_DIR,\n",
    "    profile=PROFILE,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "q19_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e891c451",
   "metadata": {},
   "source": [
    "## Q20 - Fairness Mitigation under Policy Constraints\n",
    "\n",
    "### Full Answer\n",
    "This section compares fairness before and after mitigation while enforcing explicit utility guardrails. A valid decision requires both: (1) meaningful disparity reduction, and (2) acceptable utility loss (for example bounded AUC drop).\n",
    "\n",
    "Recommended decision template:\n",
    "- Report subgroup fairness deltas (pre vs post).\n",
    "- Report utility deltas (AUC/F1/calibration).\n",
    "- Accept mitigation only if policy constraints are satisfied.\n",
    "\n",
    "Residual risks include proxy bias, intersectional disparities, and subgroup sample instability; therefore fairness monitoring must continue post-deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q20 starter\n",
    "q20_info = run_q20_fairness_mitigation(\n",
    "    df,\n",
    "    figures_dir=FIG_DIR,\n",
    "    solutions_dir=SOL_DIR,\n",
    "    profile=PROFILE,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "q20_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone - Integrated End-to-End Delivery\n",
    "\n",
    "Use this section to run a reproducible end-to-end pass after completing all question blocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = run_all(\n",
    "    DATA_PATH,\n",
    "    FIG_DIR,\n",
    "    SOL_DIR,\n",
    "    profile=PROFILE,\n",
    "    enable_q18=True,\n",
    "    enable_q19=True,\n",
    "    enable_q20=True,\n",
    ")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Checklist\n",
    "\n",
    "- [ ] Reproducibility documented (seed, versions, split logic)\n",
    "- [ ] Leakage audit documented with rationale\n",
    "- [ ] Temporal and uncertainty diagnostics completed (Q18/Q19)\n",
    "- [ ] Fairness mitigation comparison completed (Q20)\n",
    "- [ ] All required artifacts generated (CSV/JSON/PNG/PDF)\n",
    "- [ ] Executive summary and decision memo completed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
