# تمرین نهایی جامع درس علم داده (نسخه کامل فارسی)

## دانشگاه تهران - دانشکده مهندسی برق و کامپیوتر
**نیم‌سال:** بهار ۱۴۰۴  
**عنوان پروژه:** تحلیل مهاجرت جهانی استعدادهای فنی با رویکرد داده‌محور

---

## 1) مسئله و داده
- فایل داده اصلی: `code/data/GlobalTechTalent_50k.csv`
- حجم داده: 50,000 رکورد
- متغیر هدف: `Migration_Status`
- مسئله اصلی: پیش‌بینی مهاجرت حرفه‌ای افراد متخصص در حوزه فناوری

ویژگی‌های کلیدی شامل:
- `GitHub_Activity`
- `Research_Citations`
- `Industry_Experience`
- `Education_Level`
- `Country_Origin`
- و سایر متغیرهای جمعیتی/حرفه‌ای

---

## 2) خروجی‌های تحویلی الزامی
1. نوت‌بوک یکپارچه و قابل اجرا (Q1 تا Q17 + Capstone)
2. گزارش فنی نهایی با شکل‌ها و جدول‌های کامل
3. کدهای ماژولار (اسکریپت/ماژول) و فایل وابستگی‌ها
4. پاسخ‌نامه تشریحی
5. خلاصه مدیریتی کوتاه برای مخاطب غیرتخصصی

---

## 3) معیارهای پایه کیفیت
- بازتولیدپذیری کامل (`seed`، نسخه کتابخانه‌ها، دستورات اجرا)
- جلوگیری از نشت داده (`leakage`) و نشت زمانی
- تفکیک شفاف `train/validation/test`
- گزارش محدودیت‌ها، ریسک‌ها و ملاحظات اخلاقی

---

## 4) توزیع نمره (230 نمره)

| بلوک | حوزه | نمره |
|---|---|---:|
| A | مبانی: چرخه عمر، Python، EDA | 20 |
| B | استنباط آماری + طراحی مصورسازی | 20 |
| C | SQL پیشرفته + مهندسی داده | 25 |
| D | مدل‌سازی نظارت‌شده + بهینه‌سازی | 45 |
| E | یادگیری بدون نظارت | 20 |
| F | یادگیری عمیق + NLP + مدل‌های زبانی | 30 |
| G | عدالت، اخلاق، حاکمیت | 15 |
| H | کپستون یکپارچه | 25 |
| I | توسعه حرفه‌ای پایش تولید (کالیبراسیون/درفت/ریکورس) | 30 |
| J (Bonus) | افزونه‌های پژوهشی/تولیدی پیشرفته | +20 |
| **جمع بلوک‌های اصلی** |  | **230** |
| امتیاز تشویقی |  | **+20** |

---

## 5) سوالات تفصیلی

### بلوک A: مبانی (20)

### Q1) چرخه عمر علم داده و صورت‌بندی مسئله (10)
- تعریف مسئله، ذی‌نفعان، و تصمیم‌ قابل پشتیبانی با مدل
- تعریف معیارهای موفقیت فنی و عملیاتی
- تحلیل ریسک شکست در تولید (drift، quality، policy shift)
- برنامه استقرار و پایش

**خروجی:** یک سند ساختاریافته + نمودار چرخه عمر

### Q2) عملیات پایتونی، کنترل کیفیت و EDA (10)
- حسابرسی کامل نوع داده، گمشده‌ها، تکراری‌ها، پرت‌ها
- حداقل 8 نمودار تحلیلی + تفسیر کاربردی
- پیاده‌سازی یک تابع preprocessing تست‌پذیر

---

### بلوک B: استنباط و مصورسازی (20)

### Q3) طراحی مطالعه و استنباط آماری (10)
- تفکیک مشاهده‌ای/مداخله‌ای
- تعریف CI معتبر و تفسیر درست
- آزمون فرض با فرضیات و محدودیت‌های آماری

### Q4) طراحی بصری و داستان‌گویی داده (10)
- تعریف KPI های شفاف برای تصمیم‌گیر
- توجیه انتخاب رنگ، مقیاس، annotation
- مثال نمودار گمراه‌کننده + نسخه اصلاح‌شده

---

### بلوک C: SQL و مهندسی داده (25)

### Q5) SQL پیشرفته (15)
- میانگین متحرک 3 ساله با window function
- رتبه‌بندی/دهک‌بندی با rank و percentile
- تحلیل cohort با CTE

### Q6) نشت داده و معماری داده (10)
- شناسایی ویژگی‌های نشت‌دهنده و حذف مستدل
- طراحی معماری Bronze/Silver/Gold
- ارائه راهکار train-serving consistency

---

### بلوک D: مدل‌سازی نظارت‌شده و بهینه‌سازی (45)

### Q7) مدل خطی/لجستیک + Elastic Net (15)
- آموزش baseline خطی/لجستیک
- مشتق و زیرگرادیان Elastic Net
- تفسیر coefficient، p-value و CI

### Q8) مقایسه SGD، Momentum و Adam در ravine (10)
- نمایش مسیر همگرایی
- تحلیل نوسان در ابعاد با خمیدگی زیاد
- توصیه بهینه‌ساز برای داده ناهم‌مقیاس

### Q9) مقایسه خانواده مدل‌های غیرخطی (20)
- SVM/KNN
- Decision Tree/Random Forest
- Boosting (ترجیحاً XGBoost)
- CV + hyperparameter tuning + error analysis

---

### بلوک E: بدون نظارت (20)

### Q10) کاهش بُعد (10)
- PCA و Explained Variance Ratio
- یک روش مکمل (t-SNE/UMAP/Random Projection)

### Q11) خوشه‌بندی (10)
- KMeans + Elbow + Silhouette
- DBSCAN و مقایسه پایداری خوشه‌ها

---

### بلوک F: یادگیری عمیق، NLP و مدل‌های زبانی (30)

### Q12) شبکه عصبی جدولی + مدل توالی/متن (15)
- اجرای یک MLP برای داده جدولی
- اجرای یک مدل توالی/متنی (RNN/LSTM/GRU/CNN)
- مقایسه با baseline کلاسیک

### Q13) طراحی LLM Agent (15)
- جریان `plan -> retrieve -> reason -> verify`
- تعریف معیارهای faithfulness/hallucination/safety
- قیود حاکمیتی و مسیر fallback

---

### بلوک G: اخلاق و حاکمیت (15)

### Q14) عدالت، سوگیری و استقرار مسئولانه (15)
- ارزیابی زیرگروهی (کشور/تحصیلات/سابقه)
- تحلیل خطر proxy bias
- سیاست human-in-the-loop

---

### بلوک H: Capstone (25)
- پیاده‌سازی کامل pipeline از داده تا مدل
- تبیین محلی و سراسری با SHAP
- گزارش fairness slice
- توصیه عملیاتی برای استقرار و مانیتورینگ

---

### بلوک I: توسعه حرفه‌ای پایش تولید (30)

### Q15) کالیبراسیون و آستانه تصمیم (10)
- رسم calibration curve
- محاسبه Brier/ECE
- تعیین آستانه بهینه با دو رویکرد:
  - بیشینه‌سازی F1
  - کمینه‌سازی هزینه نامتقارن خطا

### Q16) Drift Monitoring (10)
- تعریف پنجره مرجع/جاری
- محاسبه PSI برای ویژگی‌های عددی
- محاسبه یک شاخص drift دسته‌ای (مثل JS divergence)
- تعریف policy برای هشدار و retrain

### Q17) Counterfactual Recourse (10)
- تحلیل موارد نزدیک آستانه منفی
- برآورد کمینه تغییر ویژگی‌های قابل‌اقدام
- گزارش recourse success rate و median intervention
- تحلیل عملی/اخلاقی مداخله‌ها

---

### بلوک J (Bonus تا +20): افزونه‌های پیچیده
- **Causal DAG و شناسایی** (۵): ترسیم گراف، بحث مجموعه تعدیل و محدودیت‌های شناسایی.  
- **عدم‌قطعیت/Conformal** (۵): پیش‌بینی بازه‌ای با پوشش تجربی گزارش‌شده.  
- **اعتبارسنجی زمانی** (۵): اسپلـیت زمانی در برابر تصادفی، تحلیل افت عملکرد.  
- **سروینگ آن‌لاین/استریمینگ** (۵): طرح ویژگی‌های تازه، SLA و نگهبان OOD/درفت.  

---

## 6) قوانین نمره‌دهی و کسر نمره
- وجود نشت داده بدون گزارش: کسر سنگین (تا 50% بلوک مرتبط)
- نبود بازتولیدپذیری: کسر تا 30% پروژه
- تفسیر نادرست p-value/CI: کسر 20-40% سوال
- حذف تحلیل عدالت/اخلاق: کسر کامل بلوک G

---

## 7) امتیاز تشویقی (تا +10)
- توسعه تحلیل علی (DAG و بحث شناسایی)
- افزودن temporal validation
- برآورد عدم‌قطعیت پیشرفته (Conformal/Bayesian Approx.)

---

## 8) منابع و انطباق سرفصل
این نسخه توسعه‌یافته برای پوشش سرفصل‌های عمومی‌شده در مخازن رسمی UT-ECE طراحی شده است:
- https://github.com/DataScience-ECE-UniversityOfTehran/DataScience-Spring2024
- https://github.com/DataScience-ECE-UniversityOfTehran/DataScience-Spring2025
